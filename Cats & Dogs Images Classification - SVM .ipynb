{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f54e09e",
   "metadata": {},
   "source": [
    "Prodigy InfoTech ML Internship - Task 3\n",
    "\n",
    "The Dataset contains 25,000 images of dogs and cats. We need to create a Support Vector Machine (SVM) Algorithm to classify each image.\n",
    "\n",
    "Objective : Train your algorithm on the files to distinguish dogs from cats and predict the labels (1 = dog, 0 = cat).\n",
    "\n",
    "Dataset : https://www.kaggle.com/competitions/dogs-vs-cats/data?select=train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86909df1",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcb01039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "import cv2\n",
    "import joblib \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f030141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "train = \"train.zip\"\n",
    "\n",
    "with ZipFile(train, 'r') as zip:\n",
    "    zip.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc3683c",
   "metadata": {},
   "source": [
    "# Some file and directory management\n",
    "Here we set up the directory structure for the dataset and the paths for saving the confusion matrix image, classification report, and trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "389808d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = f\"Dataset/\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "confusion_image_path = os.path.join(folder_path, 'confusion matrix.png')\n",
    "classification_file_path = os.path.join(folder_path, 'classification_report.txt')\n",
    "model_file_path = os.path.join(folder_path, \"svm_model.pkl\")\n",
    "\n",
    "dataset_dir = \"Dataset/\"\n",
    "train_dir = os.path.join(dataset_dir, \"train\")\n",
    "test_dir = os.path.join(dataset_dir, \"test1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fd9a3f",
   "metadata": {},
   "source": [
    "# Loading, Preprocessing, and assigning labels to the data\n",
    "Here we assign label to each image then we preprocess it and flattening it to array, and finally store images and labels into variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1acacef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing in Progress:  91%|█████████ | 22727/25000 [01:03<00:10, 216.97it/s]"
     ]
    }
   ],
   "source": [
    "images_for_train = os.listdir(train_dir)\n",
    "features = []\n",
    "labels = []\n",
    "images_size = (50,50)\n",
    "\n",
    "for image in tqdm(images_for_train, desc=\"Processing in Progress\"):\n",
    "    if image[0:3] == 'cat':\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    \n",
    "    read_image = cv2.imread(train_dir+\"/\"+image)\n",
    "    resized_image = cv2.resize(read_image, images_size)\n",
    "    normalized_image = resized_image / 255.0\n",
    "    flatten_image = normalized_image.flatten()\n",
    "    features.append(flatten_image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96fc05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As it's not required anymore\n",
    "del images_for_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab922a",
   "metadata": {},
   "source": [
    "# Split Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e61be",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.asarray(features)\n",
    "labels = np.asarray(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dbce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As it's not required anymore\n",
    "del features\n",
    "del labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10d6958",
   "metadata": {},
   "source": [
    "# Setting up a ML Pipeline \n",
    "Principal Component Analysis (PCA) is a technique used to reduce the dimensionality of data while preserving as much variability as possible, and SVM is a reliable algorithm here as it is a supervised machine learning algorithm used for classification.\n",
    "\n",
    "We created here a Pipeline to chain together the two steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f3d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is initial value Specifies that PCA should retain 80% of the variance\n",
    "components_num = 0.8 \n",
    "\n",
    "pca = PCA(n_components=components_num, random_state=42)\n",
    "svm = SVC()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('pca', pca),\n",
    "    ('svm', svm)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2df52e6",
   "metadata": {},
   "source": [
    "# Cross-Valiadtion\n",
    "During grid search, different combinations of these parameters will be tried, and the best combination will be selected based on cross-validation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa5b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'pca__n_components': [2, 1, 0.9, 0.8], # Different number of PCA components to try\n",
    "    'svm__kernel' : ['linear', 'rbf', 'poly', 'sigmoid'], # Different SVM kernels to try\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53f9aaa",
   "metadata": {},
   "source": [
    "# Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41934ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#record the starting time (before training)\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameter_grid, cv=3, verbose=4)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#record the ending time (after training)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e2974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As it's not required anymore\n",
    "del X_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e0afde",
   "metadata": {},
   "source": [
    "# Determining the best parameters & score\n",
    "The grid searching technique found that using the Radial Basis Function (RBF) kernel & retaining 90% of the variance would give us the highest accuracy of 67.38%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18fa148",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters: \", best_params)\n",
    "print(\"Best Score: \", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50119ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = best_pipeline.score(X_test, y_test)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06beec3f",
   "metadata": {},
   "source": [
    "# Testing the best model \n",
    "Here we evaluate the model performance on a test dataset, then we print a Classification Report and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64315b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "target_names = ['Cat', 'Dog']\n",
    "classification_rep = classification_report(y_test, y_pred, target_names=target_names)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "\n",
    "with open(classification_file_path, 'w') as file:\n",
    "    file.write(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e5c076",
   "metadata": {},
   "source": [
    "# Creating a Confusion Matrix\n",
    "Visualizing the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00b344",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, fmt=\"d\", cmap='binary')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.savefig(confusion_image_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca9b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
